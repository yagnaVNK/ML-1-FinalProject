{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaasa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kaasa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "torch.Size([128, 128, 6, 6])\n",
      "torch.Size([128, 128, 12, 12])\n",
      "torch.Size([128, 128, 12, 12])\n",
      "torch.Size([128, 12, 12])\n",
      "torch.Size([128, 12, 12])\n",
      "tensor(11.9850)\n"
     ]
    }
   ],
   "source": [
    "import Encoder as E\n",
    "import Decoder as D\n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.randn(16,3,28,28,device = 'cuda')\n",
    "model1 = E.ENCODER1(in_feat_dim=3,codebook_dim=128,hidden_dim=128).to(device = 'cuda')\n",
    "model2 = D.DECODER1(in_feat_dim=128,out_feat_dim=3,hidden_dim=128).to(device = 'cuda')\n",
    "\n",
    "z_e = torch.randn(128,128,6,6)\n",
    "z_e_lower = torch.randn(128,128,12,12)\n",
    "z_e_lower_tilde = torch.randn(128,128,12,12)\n",
    "\n",
    "print(z_e.shape)\n",
    "print(z_e_lower.shape)\n",
    "print(z_e_lower_tilde.shape)\n",
    "print((1-F.cosine_similarity(z_e_lower, z_e_lower_tilde, dim = 1)).shape)\n",
    "print((torch.zeros(z_e_lower.shape[0], z_e_lower.shape[2], z_e_lower.shape[2])).shape)\n",
    "print(torch.max(1-F.cosine_similarity(z_e_lower, z_e_lower_tilde, dim = 1),torch.zeros(z_e_lower.shape[0], z_e_lower.shape[2], z_e_lower.shape[2])).sum(dim=1).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type       | Params\n",
      "----------------------------------------\n",
      "0 | encoder  | ENCODER1   | 23.6 K\n",
      "1 | decoder  | DECODER1   | 56.3 K\n",
      "2 | codebook | VQCodebook | 4.1 K \n",
      "----------------------------------------\n",
      "83.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "83.9 K    Total params\n",
      "0.336     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef54c34da6d24b65bd1bc9ca85e2e9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaasa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\kaasa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363beaf77fa846668f521560cef08b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9770dcab7e4474aa2c413762171008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a04c957efd4731b960550823a3184a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065d639cc43c41378bd8f9c48b72be99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206c4359e86c40e2adef0cdc569f469a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dae866b016544d49c12322ea08a2078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import Any\n",
    "import lightning.pytorch as pl\n",
    "from torchvision.datasets import MNIST,CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import Codebook as CB\n",
    "\n",
    "training_dataset = CIFAR10(root='./data',train=True,download=True,transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.CenterCrop(24),\n",
    "            transforms.ToTensor()]))\n",
    "validation_dataset = CIFAR10(root='./data',train=False,download=True,transform=transforms.Compose([\n",
    "            transforms.CenterCrop(24),\n",
    "            transforms.ToTensor()]))\n",
    "\n",
    "training_dataloader = DataLoader(training_dataset,batch_size=128)\n",
    "validation_dataloader = DataLoader(validation_dataset,batch_size=128)\n",
    "\n",
    "class AUTOENCODER(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 input_dim = 1,\n",
    "                 hiddern_dim =128,):\n",
    "        super().__init__()\n",
    "        self.encoder = E.ENCODER1(in_feat_dim=input_dim,codebook_dim=hiddern_dim,hidden_dim=hiddern_dim).to(device = 'cuda')\n",
    "        self.decoder = D.DECODER1(in_feat_dim=hiddern_dim,out_feat_dim=input_dim,hidden_dim=hiddern_dim).to(device = 'cuda')\n",
    "        self.codebook = CB.VQCodebook(hiddern_dim,hiddern_dim,0.9)\n",
    "        self.automatic_optimization=False\n",
    "\n",
    "    def forward(self,x):\n",
    "        z_e = self.encoder(x)\n",
    "        z_q, indices, KL, Commit_loss = self.codebook.z_e_to_z_q(z_e, soft=True)\n",
    "        out = self.decoder(z_q)\n",
    "        return out ,x , z_e, indices , KL , Commit_loss\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        opt = self.optimizers()\n",
    "\n",
    "        X, _ = batch\n",
    "        d_x, _, _,indices,KL,CL = self(X)  \n",
    "        reconLoss = F.mse_loss(X, d_x)\n",
    "        loss = reconLoss + KL + CL\n",
    "        opt.zero_grad()\n",
    "        self.manual_backward(loss)\n",
    "        opt.step()\n",
    "\n",
    "        self.log(\"train_recon_loss\", reconLoss, prog_bar=True)\n",
    "        self.log(\"train_KL_loss\", KL, prog_bar=True)\n",
    "        self.log(\"train_CL_loss\", CL, prog_bar=True)\n",
    "        self.log(\"loss\", loss, prog_bar=True)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        opt = self.optimizers()\n",
    "\n",
    "        X, _ = batch\n",
    "        d_x, _, _,indices,KL,CL = self(X)  \n",
    "        reconLoss = F.mse_loss(X, d_x)\n",
    "        loss = reconLoss + KL + CL\n",
    "        \n",
    "\n",
    "        self.log(\"val_recon_loss\", reconLoss, prog_bar=True)\n",
    "        self.log(\"val_KL_loss\", KL, prog_bar=True)\n",
    "        self.log(\"val_CL_loss\", CL, prog_bar=True)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=1e-5)\n",
    "        return opt \n",
    "    \n",
    "    \n",
    "model = AUTOENCODER(3,64)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5, devices=1)\n",
    "\n",
    "trainer.fit(model, train_dataloaders=training_dataloader,\n",
    "            val_dataloaders=validation_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Select a random sample from the validation dataset\n",
    "sample_index = random.randint(0, len(validation_dataset) - 1)\n",
    "sample_image, _ = validation_dataset[sample_index]\n",
    "\n",
    "# Pass the sample through the autoencoder\n",
    "reconstructed_image, _, _,_,_,_ = model(sample_image.unsqueeze(0))  # Unsqueezing to add batch dimension\n",
    "\n",
    "# Convert PyTorch tensors to numpy arrays and remove batch dimension\n",
    "sample_image = sample_image.permute(1, 2, 0).numpy()\n",
    "reconstructed_image = reconstructed_image.squeeze(0).permute(1, 2, 0).detach().numpy()\n",
    "\n",
    "# Plot the original image and its reconstruction\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(sample_image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Reconstructed Image')\n",
    "plt.imshow(reconstructed_image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
