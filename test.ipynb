{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaasa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kaasa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "torch.Size([128, 128, 6, 6])\n",
      "torch.Size([128, 128, 12, 12])\n",
      "torch.Size([128, 128, 12, 12])\n",
      "torch.Size([128, 12, 12])\n",
      "torch.Size([128, 12, 12])\n",
      "tensor(11.9890)\n"
     ]
    }
   ],
   "source": [
    "import Encoder as E\n",
    "import Decoder as D\n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.randn(16,3,28,28,device = 'cuda')\n",
    "model1 = E.ENCODER1(in_feat_dim=3,codebook_dim=128,hidden_dim=128).to(device = 'cuda')\n",
    "model2 = D.DECODER1(in_feat_dim=128,out_feat_dim=3,hidden_dim=128).to(device = 'cuda')\n",
    "'''\n",
    "print(x.shape)\n",
    "print(model1(x).shape) \n",
    "print(model2(model1(x)).shape)\n",
    "'''\n",
    "z_e = torch.randn(128,128,6,6)\n",
    "z_e_lower = torch.randn(128,128,12,12)\n",
    "z_e_lower_tilde = torch.randn(128,128,12,12)\n",
    "\n",
    "print(z_e.shape)\n",
    "print(z_e_lower.shape)\n",
    "print(z_e_lower_tilde.shape)\n",
    "print((1-F.cosine_similarity(z_e_lower, z_e_lower_tilde, dim = 1)).shape)\n",
    "print((torch.zeros(z_e_lower.shape[0], z_e_lower.shape[2], z_e_lower.shape[2])).shape)\n",
    "print(torch.max(1-F.cosine_similarity(z_e_lower, z_e_lower_tilde, dim = 1),torch.zeros(z_e_lower.shape[0], z_e_lower.shape[2], z_e_lower.shape[2])).sum(dim=1).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Any\n",
    "import lightning.pytorch as pl\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "training_dataset = MNIST(root='./data',train=True,download=True,transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.CenterCrop(24),\n",
    "            transforms.ToTensor()]))\n",
    "validation_dataset = MNIST(root='./data',train=False,download=True,transform=transforms.Compose([\n",
    "            transforms.CenterCrop(24),\n",
    "            transforms.ToTensor()]))\n",
    "\n",
    "training_dataloader = DataLoader(training_dataset,batch_size=128)\n",
    "validation_dataloader = DataLoader(validation_dataset,batch_size=128)\n",
    "\n",
    "class AUTOENCODER(pl.LightningModule):\n",
    "    def __init__(self, \n",
    "                 input_dim = 1,\n",
    "                 hiddern_dim =128,):\n",
    "        super().__init__()\n",
    "        self.encoder = E.ENCODER1(in_feat_dim=1,codebook_dim=128,hidden_dim=128).to(device = 'cuda')\n",
    "        self.decoder = D.DECODER1(in_feat_dim=128,out_feat_dim=1,hidden_dim=128).to(device = 'cuda')\n",
    "        self.automatic_optimization=False\n",
    "\n",
    "    def forward(self,x):\n",
    "        z_e = self.encoder(x)\n",
    "        out = self.decoder(z_e)\n",
    "\n",
    "        return out ,x , z_e\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        opt = self.optimizers()\n",
    "\n",
    "        X, _ = batch\n",
    "        d_x, _, _ = self(X)  \n",
    "        loss = F.mse_loss(X, d_x)\n",
    "        opt.zero_grad()\n",
    "        self.manual_backward(loss)\n",
    "        opt.step()\n",
    "\n",
    "        self.log(\"recon_loss\", loss, prog_bar=True)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.Adam(self.parameters(), lr=1e-5)\n",
    "        return opt \n",
    "    \n",
    "    \n",
    "model = AUTOENCODER(3,64)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5, devices=1)\n",
    "\n",
    "trainer.fit(model, train_dataloaders=training_dataloader,\n",
    "            val_dataloaders=validation_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Select a random sample from the validation dataset\n",
    "sample_index = random.randint(0, len(validation_dataset) - 1)\n",
    "sample_image, _ = validation_dataset[sample_index]\n",
    "\n",
    "# Pass the sample through the autoencoder\n",
    "reconstructed_image, _, _ = model(sample_image.unsqueeze(0))  # Unsqueezing to add batch dimension\n",
    "\n",
    "# Convert PyTorch tensors to numpy arrays and remove batch dimension\n",
    "sample_image = sample_image.permute(1, 2, 0).numpy()\n",
    "reconstructed_image = reconstructed_image.squeeze(0).permute(1, 2, 0).detach().numpy()\n",
    "\n",
    "# Plot the original image and its reconstruction\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(sample_image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Reconstructed Image')\n",
    "plt.imshow(reconstructed_image)\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
